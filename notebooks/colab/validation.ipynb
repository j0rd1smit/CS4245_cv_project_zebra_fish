{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# custom code\n",
    "from zebrafish.configs import load_config\n",
    "from zebrafish.dataset import register_datasets, load_all_image_in_dataset\n",
    "from zebrafish.evaluation import coco_evaluation, coco_evaluation_all_model\n",
    "from zebrafish.model import predict\n",
    "from zebrafish.visualization import plot_prediction, plot_train_vs_validation_loss, plot_segementation, plot_segementation_vs_real\n",
    "from zebrafish.utils import is_in_main_dir\n",
    "\n",
    "#detectron\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "\n",
    "setup_logger()\n",
    "\n",
    "if \"notebooks\" in os.getcwd() and \"colab\" in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "    os.chdir(\"..\")\n",
    "    \n",
    "assert is_in_main_dir(), \"The notebook expectes you to be in the main directory\"\n",
    "\n",
    "register_datasets(\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_name = \"2020_05_24_21_44_41\"\n",
    "threshold = 0.5\n",
    "n_images = 1\n",
    "path_to_model = \"output/\" + model_name\n",
    "\n",
    "\n",
    "cfg = load_config(path_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_evaluation(cfg, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"test\"\n",
    "\n",
    "images = load_all_image_in_dataset(dataset, cfg)[:1]\n",
    "predictions = predict(cfg, images, threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, prediction in zip(images, predictions):\n",
    "    plot_prediction(image, prediction, cfg)\n",
    "    plot_segementation(image, prediction)\n",
    "    plot_segementation_vs_real(image, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_vs_validation_loss([cfg.OUTPUT_DIR], show_training_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/25 21:56:30 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'test_without_direction'. Trying to convert it to COCO format ...\n",
      "\u001b[32m[05/25 21:56:30 d2.data.datasets.coco]: \u001b[0mCached annotations in COCO format already exist: /home/jordi/Documents/Github/CS4245_cv_project_zebra_fish/output/2020_05_25_21_45_25/test_without_direction_coco_format.json\n",
      "\u001b[32m[05/25 21:56:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[05/25 21:56:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/jordi/Documents/Github/CS4245_cv_project_zebra_fish/output/2020_05_25_21_45_25/coco_instances_results.json\n",
      "\u001b[32m[05/25 21:56:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.05s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.950\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.660\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.692\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.542\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.461\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.693\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607\n",
      "\u001b[32m[05/25 21:56:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 56.978 | 95.035 | 66.031 |  nan  | 69.208 | 54.200 |\n",
      "\u001b[32m[05/25 21:56:31 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.479\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.940\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.457\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.611\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.410\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.664\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n",
      "\u001b[32m[05/25 21:56:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 47.895 | 93.984 | 45.691 |  nan  | 61.057 | 45.189 |\n",
      "\u001b[32m[05/25 21:56:31 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/25 21:56:32 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'test_direction'. Trying to convert it to COCO format ...\n",
      "\u001b[32m[05/25 21:56:32 d2.data.datasets.coco]: \u001b[0mCached annotations in COCO format already exist: /home/jordi/Documents/Github/CS4245_cv_project_zebra_fish/output/2020_05_24_21_44_41/test_direction_coco_format.json\n",
      "\u001b[32m[05/25 21:56:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[05/25 21:56:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/jordi/Documents/Github/CS4245_cv_project_zebra_fish/output/2020_05_24_21_44_41/coco_instances_results.json\n",
      "\u001b[32m[05/25 21:56:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.768\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.975\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.933\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.908\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.753\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.801\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.801\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.908\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.787\n",
      "\u001b[32m[05/25 21:56:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 76.827 | 97.525 | 93.301 |  nan  | 90.817 | 75.273 |\n",
      "\u001b[32m[05/25 21:56:33 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[05/25 21:56:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| N          | 77.298 | NE         | 69.488 | E          | 81.347 |\n",
      "| SE         | 83.861 | S          | 86.416 | SW         | 53.216 |\n",
      "| W          | 85.461 | NW         | 77.525 |            |        |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.04s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.686\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.951\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.823\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.799\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.729\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.729\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.804\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.726\n",
      "\u001b[32m[05/25 21:56:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 68.557 | 95.080 | 82.288 |  nan  | 79.937 | 68.015 |\n",
      "\u001b[32m[05/25 21:56:34 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
      "\u001b[32m[05/25 21:56:34 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| N          | 73.177 | NE         | 66.304 | E          | 81.204 |\n",
      "| SE         | 66.040 | S          | 75.569 | SW         | 42.146 |\n",
      "| W          | 81.144 | NW         | 62.871 |            |        |\n"
     ]
    }
   ],
   "source": [
    "bbox_df, segm_df = coco_evaluation_all_model(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>AP</th>\n",
       "      <th>AP50</th>\n",
       "      <th>AP75</th>\n",
       "      <th>APs</th>\n",
       "      <th>APm</th>\n",
       "      <th>APl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>output/2020_05_24_21_44_41</td>\n",
       "      <td>56.977904</td>\n",
       "      <td>95.034727</td>\n",
       "      <td>66.030804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.207921</td>\n",
       "      <td>54.200038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>output/2020_05_24_21_44_41</td>\n",
       "      <td>76.826626</td>\n",
       "      <td>97.524752</td>\n",
       "      <td>93.301361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.816832</td>\n",
       "      <td>75.273436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model         AP       AP50       AP75  APs  \\\n",
       "0  output/2020_05_24_21_44_41  56.977904  95.034727  66.030804  NaN   \n",
       "1  output/2020_05_24_21_44_41  76.826626  97.524752  93.301361  NaN   \n",
       "\n",
       "         APm        APl  \n",
       "0  69.207921  54.200038  \n",
       "1  90.816832  75.273436  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>AP</th>\n",
       "      <th>AP50</th>\n",
       "      <th>AP75</th>\n",
       "      <th>APs</th>\n",
       "      <th>APm</th>\n",
       "      <th>APl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>output/2020_05_24_21_44_41</td>\n",
       "      <td>47.895313</td>\n",
       "      <td>93.984398</td>\n",
       "      <td>45.690790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.057320</td>\n",
       "      <td>45.189191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>output/2020_05_24_21_44_41</td>\n",
       "      <td>68.556789</td>\n",
       "      <td>95.080446</td>\n",
       "      <td>82.287541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.937058</td>\n",
       "      <td>68.015058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model         AP       AP50       AP75  APs  \\\n",
       "0  output/2020_05_24_21_44_41  47.895313  93.984398  45.690790  NaN   \n",
       "1  output/2020_05_24_21_44_41  68.556789  95.080446  82.287541  NaN   \n",
       "\n",
       "         APm        APl  \n",
       "0  61.057320  45.189191  \n",
       "1  79.937058  68.015058  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
