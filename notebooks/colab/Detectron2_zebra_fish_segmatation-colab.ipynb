{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Detectron2: Train on a custom dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t995W39KWYIM"
      },
      "source": [
        "# Detectron2: Zebrafish\n",
        "\n",
        "<table align=\"left\">\n",
        "<tbody><tr><td>\n",
        "   <a target=\"_blank\" href=\"https://colab.research.google.com/github/j0rd1smit/CS4245_cv_project_zebra_fish/blob/master/notebooks/colab/Detectron2_zebra_fish_segmatation-colab.ipynb\">\n",
        "     <img src=\"https://camo.githubusercontent.com/dfbf50eed8dd2dea5f3e0beaaf2001eeca77f314/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f636f6c61625f6c6f676f5f333270782e706e67\" data-canonical-src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab\n",
        "   </a>\n",
        " </td>\n",
        "<td>\n",
        "   <a target=\"_blank\" href=\"https://github.com/j0rd1smit/CS4245_cv_project_zebra_fish/blob/master/notebooks/colab/Detectron2_zebra_fish_segmatation-colab.ipynb\">\n",
        "     <img width=\"32px\" src=\"https://camo.githubusercontent.com/9a6bfd119aeed95f13553a994f2d1cd97e033768/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f696d616765732f4769744875622d4d61726b2d333270782e706e67\" data-canonical-src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">View source on GitHub</a>\n",
        " </td>\n",
        "</tr></tbody></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RX4vF6JnWf5r"
      },
      "source": [
        "## Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XcO_y7h5-81",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "860bd6b0-fcec-4784-95b3-2920fbe2b99a"
      },
      "source": [
        "!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "!gcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.4+cu100\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.4.0%2Bcu100-cp36-cp36m-linux_x86_64.whl (723.9MB)\n",
            "\u001b[K     |████████████████████████████████| 723.9MB 25kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5+cu100\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torchvision-0.5.0%2Bcu100-cp36-cp36m-linux_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1MB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5+cu100) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.5.0+cu101\n",
            "    Uninstalling torch-1.5.0+cu101:\n",
            "      Successfully uninstalled torch-1.5.0+cu101\n",
            "  Found existing installation: torchvision 0.6.0+cu101\n",
            "    Uninstalling torchvision-0.6.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Successfully installed torch-1.4.0+cu100 torchvision-0.5.0+cu100\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (0.29.18)\n",
            "Collecting pyyaml==5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp36-cp36m-linux_x86_64.whl size=44074 sha256=21fc374b599904bc2126207210248a4f7abfecdc95f9ad91aaa10d4ba3d2c241\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-a7zt3ft6\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-a7zt3ft6\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (46.4.0)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.18)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.12.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=267016 sha256=c8b22bb061f9691fd3e28d35ddfe7f2539741eed27d5b6378da269af1fd6d17a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3c_wfgaw/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Found existing installation: pycocotools 2.0.0\n",
            "    Uninstalling pycocotools-2.0.0:\n",
            "      Successfully uninstalled pycocotools-2.0.0\n",
            "Successfully installed pycocotools-2.0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT-39YHH5-9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1003
        },
        "outputId": "f0e5e0c5-8052-440d-df40-28c6fb4cdee5"
      },
      "source": [
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/index.html\n",
            "Collecting detectron2\n",
            "\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu100/torch1.4/detectron2-0.1.3%2Bcu100-cp36-cp36m-linux_x86_64.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 1.8MB/s \n",
            "\u001b[?25hCollecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/81/3b/40e876afde9f5ffa1cfdce10565aba85b0dc2e067ed551dfb566cfee6d4d/yacs-0.1.7-py3-none-any.whl\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2) (2.2.1)\n",
            "Collecting fvcore>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/43/3a/50bb1e1b1acbf5e9b79f9f0c078cd3e9694e453a61cd0f07cc8dd1e1872f/fvcore-0.1.1.post200513.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from detectron2) (7.0.0)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2) (0.8.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2) (3.2.1)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2) (4.41.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2) (5.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.10.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.34.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.7.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.29.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (46.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (0.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.18.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2) (1.6.0.post3)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.4.5.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (3.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (1.6.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.0)\n",
            "Building wheels for collected packages: fvcore\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.1.post200513-cp36-none-any.whl size=40893 sha256=2d8dae407bd8abc1b8104eb0f5936286e0a9c157080d4350c194ed87690f4cfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/f6/77/551770c4b8cd75e9335cd0acf59c08d60a8684048b19da6702\n",
            "Successfully built fvcore\n",
            "Installing collected packages: yacs, portalocker, fvcore, mock, detectron2\n",
            "Successfully installed detectron2-0.1.3+cu100 fvcore-0.1.1.post200513 mock-4.0.2 portalocker-1.7.0 yacs-0.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5GL-w-h5-9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "04a06cf1-c2a9-48b9-bc77-dd28ff5a0768"
      },
      "source": [
        "!git clone https://github.com/j0rd1smit/CS4245_cv_project_zebra_fish.git\n",
        "!cd CS4245_cv_project_zebra_fish"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CS4245_cv_project_zebra_fish'...\n",
            "remote: Enumerating objects: 164, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (120/120), done.\u001b[K\n",
            "remote: Total 164 (delta 58), reused 128 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (164/164), 30.98 MiB | 9.88 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uLRBBxra5-9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"CS4245_cv_project_zebra_fish\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oyvHKjDWW2rb"
      },
      "source": [
        "## Train on a custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MS7uotej5-9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#General\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# custom code\n",
        "from zebrafish.configs import get_default_instance_segmentation_config, load_config\n",
        "from zebrafish.dataset import register_datasets, load_all_image_in_dataset\n",
        "from zebrafish.evaluation import coco_evaluation, coco_evaluation_all_model\n",
        "from zebrafish.model import predict\n",
        "from zebrafish.trainers import TrainingUtil\n",
        "from zebrafish.visualization import plot_prediction, plot_train_vs_validation_loss, plot_segementation, plot_segementation_vs_real\n",
        "from zebrafish.utils import is_in_main_dir\n",
        "\n",
        "#detectron\n",
        "from detectron2.utils.logger import setup_logger\n",
        "\n",
        "\n",
        "setup_logger()\n",
        "\n",
        "if \"notebooks\" in os.getcwd() and \"colab\" in os.getcwd():\n",
        "    os.chdir(\"..\")\n",
        "    os.chdir(\"..\")\n",
        "\n",
        "assert is_in_main_dir(), \"The notebook expectes you to be in the main directory\"\n",
        "\n",
        "register_datasets(\"dataset\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX5C63Qq5-9d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ce60200-48bc-447a-da58-1822ae3e5ca2"
      },
      "source": [
        "max_iter = 2000\n",
        "use_direction_classes = True\n",
        "\n",
        "# Create a new model everytime you run this cell\n",
        "cfg = get_default_instance_segmentation_config(\n",
        "    use_direction_classes,\n",
        "    max_iter=max_iter\n",
        ")\n",
        "\n",
        "# Loads an old model\n",
        "# cfg = load_config(path_to_model) # load cfg from disk\n",
        "# use_direction_classes = cfg.DATASETS.USE_DIRECTION_CLASSES # load use_direction_classes from disk"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 2\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ('val_direction',)\n",
            "  TRAIN: ('train_direction',)\n",
            "  USE_DIRECTION_CLASSES: True\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: True\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [1.0, 1.0, 1.0]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 50\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 1\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: True\n",
            "    WIDTH_PER_GROUP: 64\n",
            "  RETINANET:\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 5\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 8\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.7\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\n",
            "OUTPUT_DIR: /content/CS4245_cv_project_zebra_fish/output/2020_05_29_10_46_30\n",
            "PICKLE: /content/CS4245_cv_project_zebra_fish/output/2020_05_29_10_46_30/pickle\n",
            "SEED: 42\n",
            "SOLVER:\n",
            "  BASE_LR: 0.001\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 5\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 2000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.0033333333333333335\n",
            "  WARMUP_ITERS: 300\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: 0.0001\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 100\n",
            "  EVAL_PERIOD: 60\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJqccz_k5-9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg.SOLVER.MAX_ITER = max_iter # Increase the number of iters here if needed.\n",
        "cfg.TEST.AUG.ENABLED = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "QIjmbXcl5-92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12821
        },
        "outputId": "898b9d23-2a34-41ec-a569-ca480134f42e"
      },
      "source": [
        "resume = True # Set to true if want to continue training where use left off.\n",
        "TrainingUtil.train(cfg, resume=resume)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[05/29 10:12:26 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=9, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=32, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (predictor): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[05/29 10:12:26 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5 images left.\n",
            "\u001b[32m[05/29 10:12:26 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|     N      | 8            |     NE     | 10           |     E      | 11           |\n",
            "|     SE     | 4            |     S      | 5            |     SW     | 10           |\n",
            "|     W      | 16           |     NW     | 5            |            |              |\n",
            "|   total    | 69           |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[05/29 10:12:26 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/29 10:12:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[05/29 10:12:26 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/29 10:12:26 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[05/29 10:12:28 d2.data.detection_utils]: \u001b[0mTransformGens used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[05/29 10:12:28 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/29 10:12:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "model_final_f10217.pkl: 178MB [00:16, 11.0MB/s]                           \n",
            "'roi_heads.box_predictor.cls_score.weight' has shape (81, 1024) in the checkpoint but (9, 1024) in the model! Skipped.\n",
            "'roi_heads.box_predictor.cls_score.bias' has shape (81,) in the checkpoint but (9,) in the model! Skipped.\n",
            "'roi_heads.box_predictor.bbox_pred.weight' has shape (320, 1024) in the checkpoint but (32, 1024) in the model! Skipped.\n",
            "'roi_heads.box_predictor.bbox_pred.bias' has shape (320,) in the checkpoint but (32,) in the model! Skipped.\n",
            "'roi_heads.mask_head.predictor.weight' has shape (80, 256, 1, 1) in the checkpoint but (8, 256, 1, 1) in the model! Skipped.\n",
            "'roi_heads.mask_head.predictor.bias' has shape (80,) in the checkpoint but (8,) in the model! Skipped.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[05/29 10:12:44 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "\u001b[32m[05/29 10:13:31 d2.utils.events]: \u001b[0m eta: 1:17:20  iter: 19  total_loss: 3.600  loss_cls: 2.053  loss_box_reg: 0.791  loss_mask: 0.691  loss_rpn_cls: 0.068  loss_rpn_loc: 0.101  time: 2.3839  data_time: 0.2170  lr: 0.000066  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:14:20 d2.utils.events]: \u001b[0m eta: 1:16:33  iter: 39  total_loss: 2.566  loss_cls: 0.976  loss_box_reg: 0.779  loss_mask: 0.660  loss_rpn_cls: 0.028  loss_rpn_loc: 0.091  time: 2.4095  data_time: 0.1860  lr: 0.000133  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:15:08 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/29 10:15:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/29 10:15:08 d2.evaluation.coco_evaluation]: \u001b[0mjson_file was not found in MetaDataCatalog for 'val_direction'. Trying to convert it to COCO format ...\n",
            "\u001b[32m[05/29 10:15:08 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'val_direction' to COCO format ...)\n",
            "\u001b[32m[05/29 10:15:08 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
            "\u001b[32m[05/29 10:15:08 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 5, #annotations: 69\n",
            "\u001b[32m[05/29 10:15:08 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at '/content/CS4245_cv_project_zebra_fish/output/2020_05_29_10_12_23/inference/val_direction_coco_format.json' ...\n",
            "\u001b[32m[05/29 10:15:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 5 images\n",
            "\u001b[32m[05/29 10:15:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.305131 (0.305131 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:15:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.268230 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:15:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/29 10:15:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/CS4245_cv_project_zebra_fish/output/2020_05_29_10_12_23/inference/coco_instances_results.json\n",
            "\u001b[32m[05/29 10:15:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/29 10:15:11 d2.evaluation.coco_evaluation]: \u001b[0mNo predictions from the model!\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/29 10:15:11 d2.evaluation.coco_evaluation]: \u001b[0mNo predictions from the model!\n",
            "\u001b[32m[05/29 10:15:11 d2.engine.defaults]: \u001b[0mEvaluation results for val_direction in csv format:\n",
            "\u001b[32m[05/29 10:15:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/29 10:15:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:15:11 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
            "\u001b[32m[05/29 10:15:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[05/29 10:15:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:15:11 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
            "\u001b[32m[05/29 10:15:12 d2.utils.events]: \u001b[0m eta: 1:15:57  iter: 59  total_loss: 2.211  loss_cls: 0.804  loss_box_reg: 0.752  loss_mask: 0.599  loss_rpn_cls: 0.010  loss_rpn_loc: 0.075  validation_loss: 2.523  time: 2.4071  data_time: 0.2036  lr: 0.000199  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:15:59 d2.utils.events]: \u001b[0m eta: 1:14:57  iter: 79  total_loss: 2.114  loss_cls: 0.720  loss_box_reg: 0.752  loss_mask: 0.553  loss_rpn_cls: 0.010  loss_rpn_loc: 0.068  validation_loss: 2.523  time: 2.3835  data_time: 0.2032  lr: 0.000266  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:16:46 d2.utils.events]: \u001b[0m eta: 1:14:00  iter: 99  total_loss: 1.969  loss_cls: 0.706  loss_box_reg: 0.729  loss_mask: 0.499  loss_rpn_cls: 0.009  loss_rpn_loc: 0.065  validation_loss: 2.523  time: 2.3778  data_time: 0.1349  lr: 0.000332  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:17:33 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/29 10:17:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[05/29 10:17:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 5 images\n",
            "\u001b[32m[05/29 10:17:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.304883 (0.304883 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:17:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.267312 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:17:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/29 10:17:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/CS4245_cv_project_zebra_fish/output/2020_05_29_10_12_23/inference/coco_instances_results.json\n",
            "\u001b[32m[05/29 10:17:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/29 10:17:35 d2.evaluation.coco_evaluation]: \u001b[0mNo predictions from the model!\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/29 10:17:35 d2.evaluation.coco_evaluation]: \u001b[0mNo predictions from the model!\n",
            "\u001b[32m[05/29 10:17:35 d2.engine.defaults]: \u001b[0mEvaluation results for val_direction in csv format:\n",
            "\u001b[32m[05/29 10:17:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/29 10:17:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:17:35 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
            "\u001b[32m[05/29 10:17:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[05/29 10:17:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:17:35 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
            "\u001b[32m[05/29 10:17:37 d2.utils.events]: \u001b[0m eta: 1:13:15  iter: 119  total_loss: 1.855  loss_cls: 0.610  loss_box_reg: 0.722  loss_mask: 0.453  loss_rpn_cls: 0.006  loss_rpn_loc: 0.062  validation_loss: 2.216  time: 2.3733  data_time: 0.1921  lr: 0.000399  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:18:24 d2.utils.events]: \u001b[0m eta: 1:12:42  iter: 139  total_loss: 1.716  loss_cls: 0.575  loss_box_reg: 0.659  loss_mask: 0.403  loss_rpn_cls: 0.006  loss_rpn_loc: 0.060  validation_loss: 2.216  time: 2.3692  data_time: 0.1621  lr: 0.000465  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:19:12 d2.utils.events]: \u001b[0m eta: 1:12:16  iter: 159  total_loss: 1.554  loss_cls: 0.508  loss_box_reg: 0.627  loss_mask: 0.330  loss_rpn_cls: 0.004  loss_rpn_loc: 0.056  validation_loss: 2.216  time: 2.3762  data_time: 0.1490  lr: 0.000532  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:19:58 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/29 10:19:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[05/29 10:19:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 5 images\n",
            "\u001b[32m[05/29 10:20:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.306753 (0.306753 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:20:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.268162 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:20:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/29 10:20:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/CS4245_cv_project_zebra_fish/output/2020_05_29_10_12_23/inference/coco_instances_results.json\n",
            "\u001b[32m[05/29 10:20:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/29 10:20:01 d2.evaluation.coco_evaluation]: \u001b[0mNo predictions from the model!\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/29 10:20:01 d2.evaluation.coco_evaluation]: \u001b[0mNo predictions from the model!\n",
            "\u001b[32m[05/29 10:20:01 d2.engine.defaults]: \u001b[0mEvaluation results for val_direction in csv format:\n",
            "\u001b[32m[05/29 10:20:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/29 10:20:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:20:01 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
            "\u001b[32m[05/29 10:20:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[05/29 10:20:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:20:01 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
            "\u001b[32m[05/29 10:20:03 d2.utils.events]: \u001b[0m eta: 1:11:16  iter: 179  total_loss: 1.346  loss_cls: 0.492  loss_box_reg: 0.527  loss_mask: 0.277  loss_rpn_cls: 0.004  loss_rpn_loc: 0.054  validation_loss: 1.910  time: 2.3671  data_time: 0.1775  lr: 0.000598  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:20:50 d2.utils.events]: \u001b[0m eta: 1:10:33  iter: 199  total_loss: 1.325  loss_cls: 0.442  loss_box_reg: 0.509  loss_mask: 0.266  loss_rpn_cls: 0.006  loss_rpn_loc: 0.053  validation_loss: 1.910  time: 2.3652  data_time: 0.1816  lr: 0.000664  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:21:36 d2.utils.events]: \u001b[0m eta: 1:09:21  iter: 219  total_loss: 1.137  loss_cls: 0.422  loss_box_reg: 0.431  loss_mask: 0.252  loss_rpn_cls: 0.003  loss_rpn_loc: 0.054  validation_loss: 1.910  time: 2.3606  data_time: 0.1736  lr: 0.000731  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:22:24 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/29 10:22:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[05/29 10:22:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 5 images\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.348138 (0.348138 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.284976 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/CS4245_cv_project_zebra_fish/output/2020_05_29_10_12_23/inference/coco_instances_results.json\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.120\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.139\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.307\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.114\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.052\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.125\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.306\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.118\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 12.005 | 17.946 | 13.918 |  nan  | 30.693 | 11.435 |\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP    | category   | AP    |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:------|\n",
            "| N          | 50.660 | NE         | 0.000 | E          | 0.000 |\n",
            "| SE         | 0.000  | S          | 0.000 | SW         | 0.000 |\n",
            "| W          | 45.380 | NW         | 0.000 |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.077\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.139\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.070\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.164\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.275\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.078\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n",
            "| 7.735 | 13.944 | 6.960  |  nan  | 16.415 | 7.389 |\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP    | category   | AP    |\n",
            "|:-----------|:-------|:-----------|:------|:-----------|:------|\n",
            "| N          | 26.073 | NE         | 0.000 | E          | 0.000 |\n",
            "| SE         | 0.000  | S          | 0.000 | SW         | 0.000 |\n",
            "| W          | 35.806 | NW         | 0.000 |            |       |\n",
            "\u001b[32m[05/29 10:22:27 d2.engine.defaults]: \u001b[0mEvaluation results for val_direction in csv format:\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.testing]: \u001b[0mcopypaste: 12.0050,17.9455,13.9176,nan,30.6931,11.4354\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:22:27 d2.evaluation.testing]: \u001b[0mcopypaste: 7.7348,13.9439,6.9598,nan,16.4150,7.3886\n",
            "\u001b[32m[05/29 10:22:28 d2.utils.events]: \u001b[0m eta: 1:08:34  iter: 239  total_loss: 1.154  loss_cls: 0.433  loss_box_reg: 0.439  loss_mask: 0.253  loss_rpn_cls: 0.001  loss_rpn_loc: 0.052  validation_loss: 1.654  time: 2.3637  data_time: 0.2066  lr: 0.000797  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:23:14 d2.utils.events]: \u001b[0m eta: 1:07:45  iter: 259  total_loss: 1.136  loss_cls: 0.463  loss_box_reg: 0.406  loss_mask: 0.235  loss_rpn_cls: 0.003  loss_rpn_loc: 0.051  validation_loss: 1.654  time: 2.3567  data_time: 0.1408  lr: 0.000864  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:24:01 d2.utils.events]: \u001b[0m eta: 1:06:59  iter: 279  total_loss: 1.049  loss_cls: 0.409  loss_box_reg: 0.370  loss_mask: 0.243  loss_rpn_cls: 0.001  loss_rpn_loc: 0.047  validation_loss: 1.654  time: 2.3574  data_time: 0.1542  lr: 0.000930  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:24:49 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/29 10:24:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[05/29 10:24:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 5 images\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.348654 (0.348654 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.276816 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/CS4245_cv_project_zebra_fish/output/2020_05_29_10_12_23/inference/coco_instances_results.json\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.095\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.080\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.100\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.172\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.083\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n",
            "| 9.504 | 15.842 | 8.034  |  nan  | 17.137 | 7.762 |\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| N          | 14.158 | NE         | 13.564 | E          | 24.282 |\n",
            "| SE         | 0.000  | S          | 0.000  | SW         | 0.000  |\n",
            "| W          | 24.026 | NW         | 0.000  |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.119\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.185\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.078\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.061\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.096\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.185\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.081\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n",
            "| 9.344 | 15.842 | 11.881 |  nan  | 18.490 | 7.774 |\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| N          | 9.010  | NE         | 13.020 | E          | 26.634 |\n",
            "| SE         | 0.000  | S          | 0.000  | SW         | 0.000  |\n",
            "| W          | 26.089 | NW         | 0.000  |            |        |\n",
            "\u001b[32m[05/29 10:24:51 d2.engine.defaults]: \u001b[0mEvaluation results for val_direction in csv format:\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.testing]: \u001b[0mcopypaste: 9.5039,15.8416,8.0342,nan,17.1370,7.7620\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:24:51 d2.evaluation.testing]: \u001b[0mcopypaste: 9.3441,15.8416,11.8812,nan,18.4901,7.7735\n",
            "\u001b[32m[05/29 10:24:53 d2.utils.events]: \u001b[0m eta: 1:06:10  iter: 299  total_loss: 1.054  loss_cls: 0.362  loss_box_reg: 0.409  loss_mask: 0.225  loss_rpn_cls: 0.003  loss_rpn_loc: 0.051  validation_loss: 1.398  time: 2.3580  data_time: 0.1495  lr: 0.000997  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:25:40 d2.utils.events]: \u001b[0m eta: 1:05:22  iter: 319  total_loss: 1.010  loss_cls: 0.368  loss_box_reg: 0.370  loss_mask: 0.194  loss_rpn_cls: 0.004  loss_rpn_loc: 0.046  validation_loss: 1.398  time: 2.3561  data_time: 0.2166  lr: 0.001000  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:26:28 d2.utils.events]: \u001b[0m eta: 1:04:35  iter: 339  total_loss: 0.933  loss_cls: 0.279  loss_box_reg: 0.369  loss_mask: 0.200  loss_rpn_cls: 0.001  loss_rpn_loc: 0.047  validation_loss: 1.398  time: 2.3594  data_time: 0.1557  lr: 0.001000  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:27:17 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/29 10:27:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[05/29 10:27:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 5 images\n",
            "\u001b[32m[05/29 10:27:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.350181 (0.350181 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:27:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.267339 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:27:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/29 10:27:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/CS4245_cv_project_zebra_fish/output/2020_05_29_10_12_23/inference/coco_instances_results.json\n",
            "\u001b[32m[05/29 10:27:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.179\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.267\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.243\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.163\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.086\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.191\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.191\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.177\n",
            "\u001b[32m[05/29 10:27:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 17.941 | 26.700 | 24.255 |  nan  | 34.480 | 16.346 |\n",
            "\u001b[32m[05/29 10:27:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[05/29 10:27:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP    |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:------|\n",
            "| N          | 24.719 | NE         | 49.173 | E          | 6.931 |\n",
            "| SE         | 0.000  | S          | 0.000  | SW         | 0.000 |\n",
            "| W          | 62.703 | NW         | 0.000  |            |       |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.02s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.267\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.197\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.274\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.077\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.170\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.281\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
            "\u001b[32m[05/29 10:27:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 15.834 | 26.700 | 19.676 |  nan  | 27.351 | 14.692 |\n",
            "\u001b[32m[05/29 10:27:19 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[05/29 10:27:19 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category   | AP    |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:------|\n",
            "| N          | 17.723 | NE         | 39.835 | E          | 6.931 |\n",
            "| SE         | 0.000  | S          | 0.000  | SW         | 0.000 |\n",
            "| W          | 62.184 | NW         | 0.000  |            |       |\n",
            "\u001b[32m[05/29 10:27:20 d2.engine.defaults]: \u001b[0mEvaluation results for val_direction in csv format:\n",
            "\u001b[32m[05/29 10:27:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/29 10:27:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:27:20 d2.evaluation.testing]: \u001b[0mcopypaste: 17.9408,26.6997,24.2554,nan,34.4802,16.3458\n",
            "\u001b[32m[05/29 10:27:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[05/29 10:27:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:27:20 d2.evaluation.testing]: \u001b[0mcopypaste: 15.8341,26.6997,19.6762,nan,27.3515,14.6922\n",
            "\u001b[32m[05/29 10:27:21 d2.utils.events]: \u001b[0m eta: 1:03:49  iter: 359  total_loss: 0.931  loss_cls: 0.314  loss_box_reg: 0.357  loss_mask: 0.186  loss_rpn_cls: 0.002  loss_rpn_loc: 0.047  validation_loss: 1.323  time: 2.3640  data_time: 0.1910  lr: 0.001000  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:28:07 d2.utils.events]: \u001b[0m eta: 1:03:02  iter: 379  total_loss: 0.861  loss_cls: 0.249  loss_box_reg: 0.366  loss_mask: 0.178  loss_rpn_cls: 0.001  loss_rpn_loc: 0.044  validation_loss: 1.323  time: 2.3608  data_time: 0.1819  lr: 0.001000  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:28:55 d2.utils.events]: \u001b[0m eta: 1:02:17  iter: 399  total_loss: 0.879  loss_cls: 0.254  loss_box_reg: 0.368  loss_mask: 0.194  loss_rpn_cls: 0.003  loss_rpn_loc: 0.042  validation_loss: 1.323  time: 2.3630  data_time: 0.1521  lr: 0.001000  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:29:43 d2.data.common]: \u001b[0mSerializing 5 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[05/29 10:29:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.02 MiB\n",
            "\u001b[32m[05/29 10:29:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 5 images\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:00.377504 (0.377504 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:00 (0.278998 s / img per device, on 1 devices)\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /content/CS4245_cv_project_zebra_fish/output/2020_05_29_10_12_23/inference/coco_instances_results.json\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.538\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.423\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.566\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.337\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.565\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.361\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 34.714 | 53.837 | 42.326 |  nan  | 56.609 | 33.706 |\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| N          | 63.437 | NE         | 47.279 | E          | 62.416 |\n",
            "| SE         | 20.594 | S          | 0.000  | SW         | 25.083 |\n",
            "| W          | 58.901 | NW         | 0.000  |            |        |\n",
            "Loading and preparing results...\n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n",
            "DONE (t=0.03s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.03s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.318\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.485\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.387\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.564\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.314\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.161\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.571\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.339\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 31.821 | 48.531 | 38.746 |  nan  | 56.411 | 31.406 |\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.coco_evaluation]: \u001b[0mNote that some metrics cannot be computed.\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
            "| category   | AP     | category   | AP     | category   | AP     |\n",
            "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
            "| N          | 64.158 | NE         | 30.663 | E          | 58.669 |\n",
            "| SE         | 15.446 | S          | 0.000  | SW         | 17.195 |\n",
            "| W          | 68.441 | NW         | 0.000  |            |        |\n",
            "\u001b[32m[05/29 10:29:46 d2.engine.defaults]: \u001b[0mEvaluation results for val_direction in csv format:\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.testing]: \u001b[0mcopypaste: 34.7137,53.8366,42.3257,nan,56.6089,33.7055\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: segm\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
            "\u001b[32m[05/29 10:29:46 d2.evaluation.testing]: \u001b[0mcopypaste: 31.8214,48.5314,38.7465,nan,56.4109,31.4057\n",
            "\u001b[32m[05/29 10:29:47 d2.utils.events]: \u001b[0m eta: 1:01:32  iter: 419  total_loss: 0.885  loss_cls: 0.228  loss_box_reg: 0.405  loss_mask: 0.180  loss_rpn_cls: 0.002  loss_rpn_loc: 0.041  validation_loss: 1.247  time: 2.3631  data_time: 0.1943  lr: 0.001000  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:30:33 d2.utils.events]: \u001b[0m eta: 1:00:43  iter: 439  total_loss: 0.846  loss_cls: 0.276  loss_box_reg: 0.341  loss_mask: 0.169  loss_rpn_cls: 0.002  loss_rpn_loc: 0.038  validation_loss: 1.247  time: 2.3601  data_time: 0.1641  lr: 0.001000  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:31:21 d2.utils.events]: \u001b[0m eta: 0:59:55  iter: 459  total_loss: 0.888  loss_cls: 0.245  loss_box_reg: 0.321  loss_mask: 0.180  loss_rpn_cls: 0.002  loss_rpn_loc: 0.039  validation_loss: 1.247  time: 2.3607  data_time: 0.1451  lr: 0.001000  max_mem: 5047M\n",
            "\u001b[32m[05/29 10:31:28 d2.engine.hooks]: \u001b[0mOverall training speed: 460 iterations in 0:18:08 (2.3658 s / it)\n",
            "\u001b[32m[05/29 10:31:28 d2.engine.hooks]: \u001b[0mTotal training time: 0:18:39 (0:00:31 on hooks)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1de8b0a811e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;31m# Set to true if want to continue training where use left off.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mTrainingUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/CS4245_cv_project_zebra_fish/zebrafish/trainers/TrainingUtil.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cfg, resume)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCocoTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \"\"\"\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPECTED_RESULTS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             assert hasattr(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdo\u001b[0m \u001b[0msomething\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \"\"\"\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/modeling/meta_arch/rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproposal_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproposal_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m\"proposals\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatched_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/modeling/proposal_generator/rpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, features, gt_instances)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_and_sample_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mgt_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_no_grad\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_no_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/modeling/proposal_generator/rpn.py\u001b[0m in \u001b[0;36mlabel_and_sample_anchors\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mmatch_quality_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry_if_cuda_oom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairwise_iou\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_boxes_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmatched_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_labels_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry_if_cuda_oom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_matcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_quality_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;31m# Matching is memory-expensive and may result in CPU tensors. But the result is small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mgt_labels_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt_labels_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgt_boxes_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/utils/memory.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_ignore_torch_cuda_oom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Clear cache and retry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/detectron2/modeling/matcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, match_quality_matrix)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_matches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_match_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_quality_matrix\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# match_quality_matrix is M (gt) x N (predicted)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nHO4nM-V5-99",
        "colab_type": "text"
      },
      "source": [
        "## Learning curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-51VNVUm5-9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_train_vs_validation_loss([cfg.OUTPUT_DIR], show_training_loss=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AjmhnJFpX2RJ",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1MO96XZs5--E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coco_evaluation(cfg, dataset_name=\"test\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI4uF2hR5--K",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation against other models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "oc2i8A4d5--O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bbox_df, segm_df = coco_evaluation_all_model(\"test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "M5Hro2wV5--Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bbox_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "i-Juiixb5--d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "segm_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9NBAgbd5--i",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjeR-ngC5--j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yn7fTVREXvj0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Visualization\n",
        "Here we display the prediction for the unseen test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P4V9iyTtll8D",
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "threshold = 0.75\n",
        "n_images = 10\n",
        "dataset = \"test\"\n",
        "\n",
        "images = load_all_image_in_dataset(dataset, cfg)[:n_images]\n",
        "predictions = predict(cfg, images, threshold=threshold)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0CKKvqs5--w",
        "colab_type": "text"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "dYLrqY_o5--x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for image, prediction in zip(images, predictions):\n",
        "    plot_prediction(image, prediction, cfg)\n",
        "    plot_segementation(image, prediction)\n",
        "    plot_segementation_vs_real(image, prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mCJ8ms15--5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}